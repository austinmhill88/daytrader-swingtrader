# AI Coder Configuration
# Local AI runtime with unrestricted web access and controlled file access

# Model registry (GGUF files)
# For Windows with NVIDIA RTX 5070, set gpu_layers: -1 for full GPU acceleration
models:
  - alias: "qwen2.5:3b-instruct"
    gguf_path: "${MODELS_DIR}/qwen2.5-3b-instruct-q4_k_m.gguf"
    ctx_size: 2048
    gpu_layers: -1  # -1 = all layers on GPU (RTX 5070)
  
  # Example: Add more models as needed
  # - alias: "llama3.2:3b-instruct"
  #   gguf_path: "${MODELS_DIR}/llama-3.2-3b-instruct-q4_k_m.gguf"
  #   ctx_size: 2048
  #   gpu_layers: -1

# Default model to use when none specified
default_model: "qwen2.5:3b-instruct"

# Network access (set false to fully air-gap)
allow_network: true

# File sandbox - restricts all file operations to this root
# Use environment variable or absolute path
root_dir: "${DAYTRADER_ROOT}"

# Write policy (disabled by default for safety)
allow_write: false

# Allowlist: patterns relative to root_dir that CAN be accessed
allowed_globs:
  - "src/**/*.py"
  - "server/**/*.py"
  - "config/**/*.yaml"
  - "logs/**/*.log"
  - "README.md"
  - "docs/**/*.md"
  - "backtest/**/*.py"
  - "gui/**/*.py"

# Denylist: patterns that CANNOT be accessed (takes precedence)
denied_globs:
  - ".env"
  - ".env.*"
  - "config/**/secrets*"
  - "config/**/keys*"
  - "**/*.pem"
  - "**/*.key"
  - "**/id_rsa*"
  - "**/*.db"  # Prevent direct database access

# Default runtime options for model inference
runtime_defaults:
  temperature: 0.3      # Lower = more focused, higher = more creative
  top_p: 0.9           # Nucleus sampling
  top_k: 40            # Top-k sampling
  repeat_penalty: 1.1  # Penalize repetition
  num_ctx: 2048        # Context window size
  num_predict: 320     # Max tokens to generate (increase for longer responses)

# Optional: SearxNG search integration
# Set SEARXNG_URL environment variable to enable web search
# Example: SEARXNG_URL=http://localhost:8080
